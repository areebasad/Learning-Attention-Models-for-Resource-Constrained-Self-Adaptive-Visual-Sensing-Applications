{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47cba7f7-10e0-4c88-a83a-81a99c9c8512",
   "metadata": {},
   "source": [
    "This notebook shows how to perform a single inference on:\n",
    "\n",
    "1. Cloud\n",
    "2. Locally"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de65ca8-384c-4d49-98af-46a93b5c2d4b",
   "metadata": {},
   "source": [
    "### Inference on Cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89787a5b-7132-4a09-a34e-ca9ca69b6e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To run inference on NTNU cloud\n",
    "## only for testing purpose\n",
    "\n",
    "\n",
    "import grpc                    # for cloud inference\n",
    "#import yolov5_service_pb2      # for cloud inference\n",
    "#import yolov5_service_pb2_grpc # for cloud inference\n",
    "import pipeline_pb2_grpc       # for cloud visualization\n",
    "import pipeline_pb2            # for cloud visualization\n",
    "from PIL import Image, ImageFile\n",
    "from functions import image_to_byte_array\n",
    "from icecream import ic\n",
    "\n",
    "_YOLO_PORT = 8055\n",
    "_VIS_PORT = 8056\n",
    "\n",
    "\n",
    "yolo_channel = grpc.insecure_channel(\"ai4eu.idi.ntnu.no:\" + str(_YOLO_PORT))\n",
    "yolo_stub = pipeline_pb2_grpc.YoloV5Stub(yolo_channel)\n",
    "\n",
    "visualization_channel = grpc.insecure_channel(\"ai4eu.idi.ntnu.no:\" + str(_VIS_PORT))\n",
    "visualization_stub = pipeline_pb2_grpc.VisualizationServiceStub(visualization_channel)\n",
    "\n",
    "\n",
    "image_path = '../utils/reference-images/jervskogen_1_2021-12-11_11-30-03.png'  # or file, Path, PIL, OpenCV, numpy, list\n",
    "\n",
    "image = Image.open(image_path)\n",
    "\n",
    "\n",
    " # (B) Do inference on cloud and send image... \n",
    "request = pipeline_pb2.Image(data = image_to_byte_array(image))\n",
    "detected_objects = yolo_stub.detect(request) \n",
    "#detected_objects = detected_objects.objects\n",
    "\n",
    "ic(detected_objects)\n",
    "request = pipeline_pb2.ImageWithObjects(image = pipeline_pb2.Image(data = image_to_byte_array(image)),objects = detected_objects)\n",
    "\n",
    "\n",
    "\n",
    "visualization_stub.Visualize(request)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dec8bf9-5296-44d7-8421-4c43e9017c27",
   "metadata": {},
   "source": [
    "### Local Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d4c43fe-2e32-4a62-9d58-5925e04adf10",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/ultralytics/yolov5/archive/master.zip\" to /Users/areeb/.cache/torch/hub/master.zip\n",
      "fatal: not a git repository (or any of the parent directories): .git\n",
      "YOLOv5 ðŸš€ 2022-3-31 torch 1.10.2 CPU\n",
      "\n",
      "Fusing layers... \n",
      "[W NNPACK.cpp:79] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients, 16.5 GFLOPs\n",
      "Adding AutoShape... \n",
      "image 1/1: 1080x1920 3 persons\n",
      "Speed: 65.1ms pre-process, 310.2ms inference, 1.2ms NMS per image at shape (1, 3, 384, 640)\n",
      "ic| type(results.pandas()): <class 'models.common.Detections'>\n",
      "ic| results.pandas().xyxyn[0]:        xmin      ymin      xmax      ymax  confidence  class    name\n",
      "                               0  0.605944  0.130734  0.619040  0.172764    0.382782      0  person\n",
      "                               1  0.478418  0.090557  0.486682  0.119556    0.244386      0  person\n",
      "                               2  0.932291  0.559586  0.948298  0.600477    0.205561      0  person\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "# To run model on local machine\n",
    "# Take image, run inference and show results\n",
    "## Only for testing purpose\n",
    "\n",
    "# Images\n",
    "image_path = '../utils/reference-images/jervskogen_1_2021-12-11_11-30-03.png'  # or file, Path, PIL, OpenCV, numpy, list\n",
    "\n",
    "# Model, downloads model from hub and stores the model file with weights in the same directory\n",
    "model = torch.hub.load('ultralytics/yolov5', 'yolov5s', force_reload=True, pretrained=True)  # or yolov5m, yolov5l, yolov5x, custom\n",
    "model.conf = 0.2\n",
    "# Yolo Inference\n",
    "results = model(image_path, size=640)\n",
    "\n",
    "# Results\n",
    "results.print()  # or .print() .show(), .save(), .crop(), .pandas(), etc.\n",
    "ic(type(results.pandas()))\n",
    "ic(results.pandas().xyxyn[0])\n",
    "results.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ec9124-b84c-4cfd-a80c-8721b1988c00",
   "metadata": {},
   "source": [
    "#### Playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33621447-fce8-4e30-8fd5-70833ebe807c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The below code is just to test the resizing of an image, will be removed\n",
    "# Images\n",
    "im_pth = '../utils/reference-images/jervskogen_1_2021-12-11_11-30-03.png'\n",
    "\n",
    "desired_size = 640\n",
    "#im_pth = \"/home/jdhao/test.jpg\"\n",
    "\n",
    "im = Image.open(im_pth)\n",
    "old_size = im.size  # old_size[0] is in (width, height) format\n",
    "\n",
    "ratio = float(desired_size)/max(old_size)\n",
    "new_size = tuple([int(x*ratio) for x in old_size])\n",
    "# use thumbnail() or resize() method to resize the input image\n",
    "\n",
    "# thumbnail is a in-place operation\n",
    "\n",
    "# im.thumbnail(new_size, Image.ANTIALIAS)\n",
    "\n",
    "im = im.resize(new_size, Image.ANTIALIAS)\n",
    "# create a new image and paste the resized on it\n",
    "\n",
    "new_im = Image.new(\"RGB\", (desired_size, desired_size))\n",
    "new_im.paste(im, ((desired_size-new_size[0])//2,\n",
    "                    (desired_size-new_size[1])//2))\n",
    "new_im.size\n",
    "\n",
    "#new_im.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolo_env",
   "language": "python",
   "name": "yolo_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
